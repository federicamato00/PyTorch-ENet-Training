{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicamato00/PyTorch-ENet-Training/blob/master/Training_ENet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4lDGtuBfbLN"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/federicamato00/PyTorch-ENet-Training.git\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/PyTorch-ENet-Training/data\n",
        "#Download Cityscapes Dataset\n",
        "!python -m pip install cityscapesscripts\n",
        "!csDownload leftImg8bit_trainvaltest.zip\n",
        "!csDownload gtFine_trainvaltest.zip\n",
        "%mkdir /content/PyTorch-ENet-Training/data/Cityscapes/\n",
        "%cd /content/PyTorch-ENet-Training/data\n",
        "\n",
        "\n",
        "!unzip leftImg8bit_trainvaltest.zip -d /content/PyTorch-ENet-Training/data/Cityscapes/\n",
        "!unzip gtFine_trainvaltest.zip -d /content/PyTorch-ENet-Training/data/Cityscapes/"
      ],
      "metadata": {
        "id": "dBzqdW47fgao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/PyTorch-ENet-Training/data/Cityscapes\n",
        "!CITYSCAPES_DATASET='.' csCreateTrainIdLabelImgs\n",
        "%cd /content/PyTorch-ENet-Training\n",
        "!pip install visdom\n",
        "%mkdir /content/PyTorch-ENet-Training/save/final_model"
      ],
      "metadata": {
        "id": "MgMBfIRkfpxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################Training####################\n",
        "%cd /content/PyTorch-ENet-Training\n",
        "\n",
        "!python main.py -m train --save-dir /content/PyTorch-ENet-Training/save/final_model/ --name ENet --dataset cityscapes --dataset-dir /content/PyTorch-ENet-Training/data/Cityscapes/ --with-unlabeled --epochs 25 --batch-size 30\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCqicqjcfsWp",
        "outputId": "9db8a21a-7eb8-4c70-ec70-383e1909eb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch-ENet-Training\n",
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: cityscapes\n",
            "Dataset directory: /content/PyTorch-ENet-Training/data/Cityscapes/\n",
            "Save directory: /content/PyTorch-ENet-Training/save/final_model/\n",
            "train_set:\n",
            "/content/PyTorch-ENet-Training/data/Cityscapes/\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Number of classes to predict: 20\n",
            "Train dataset size: 2975\n",
            "Validation dataset size: 500\n",
            "100\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "Image size: torch.Size([30, 3, 360, 480])\n",
            "Label size: torch.Size([30, 360, 480])\n",
            "Class-color encoding: OrderedDict([('unlabeled', (0, 0, 0)), ('road', (128, 64, 128)), ('sidewalk', (244, 35, 232)), ('building', (70, 70, 70)), ('wall', (102, 102, 156)), ('fence', (190, 153, 153)), ('pole', (153, 153, 153)), ('traffic_light', (250, 170, 30)), ('traffic_sign', (220, 220, 0)), ('vegetation', (107, 142, 35)), ('terrain', (152, 251, 152)), ('sky', (70, 130, 180)), ('person', (220, 20, 60)), ('rider', (255, 0, 0)), ('car', (0, 0, 142)), ('truck', (0, 0, 70)), ('bus', (0, 60, 100)), ('train', (0, 80, 100)), ('motorcycle', (0, 0, 230)), ('bicycle', (119, 11, 32))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "Class weights: tensor([ 1.7027, 40.6602,  6.6971, 32.9850, 47.6814, 12.6795, 48.4036, 50.4983,\n",
            "        50.4983, 50.4983, 50.4983, 50.4983, 50.4983, 50.4983, 50.4983, 50.4983,\n",
            "        50.4983, 50.4983, 50.4983, 50.4983], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "ENet(\n",
            "  (initial_block): InitialBlock(\n",
            "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample1_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample2_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_8): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_0): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (upsample4_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (upsample5_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular5_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (transposed_conv): ConvTranspose2d(16, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 0] Avg. loss: 2.1650 | Mean IoU: 0.0401\n",
            ">>>> [Epoch: 1] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 1] Avg. loss: 1.1442 | Mean IoU: 0.2522\n",
            ">>>> [Epoch: 2] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 2] Avg. loss: 0.8235 | Mean IoU: 0.3020\n",
            ">>>> [Epoch: 3] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 3] Avg. loss: 0.6713 | Mean IoU: 0.3230\n",
            ">>>> [Epoch: 4] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 4] Avg. loss: 0.5900 | Mean IoU: 0.3425\n",
            ">>>> [Epoch: 5] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 5] Avg. loss: 0.5341 | Mean IoU: 0.3557\n",
            ">>>> [Epoch: 6] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 6] Avg. loss: 0.4904 | Mean IoU: 0.3674\n",
            ">>>> [Epoch: 7] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 7] Avg. loss: 0.4757 | Mean IoU: 0.3711\n",
            ">>>> [Epoch: 8] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 8] Avg. loss: 0.4441 | Mean IoU: 0.3802\n",
            ">>>> [Epoch: 9] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 9] Avg. loss: 0.4280 | Mean IoU: 0.3844\n",
            ">>>> [Epoch: 9] Validation\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 9] Avg. loss: 0.4667 | Mean IoU: 0.3741\n",
            "unlabeled: 0.8521\n",
            "road: 0.0889\n",
            "sidewalk: 0.7523\n",
            "building: 0.2553\n",
            "wall: 0.0000\n",
            "fence: 0.6686\n",
            "pole: 0.0014\n",
            "traffic_light: nan\n",
            "traffic_sign: nan\n",
            "vegetation: nan\n",
            "terrain: nan\n",
            "sky: nan\n",
            "person: nan\n",
            "rider: nan\n",
            "car: nan\n",
            "truck: nan\n",
            "bus: nan\n",
            "train: nan\n",
            "motorcycle: nan\n",
            "bicycle: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 10] Avg. loss: 0.4150 | Mean IoU: 0.3887\n",
            ">>>> [Epoch: 11] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 11] Avg. loss: 0.3919 | Mean IoU: 0.3981\n",
            ">>>> [Epoch: 12] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 12] Avg. loss: 0.3826 | Mean IoU: 0.4023\n",
            ">>>> [Epoch: 13] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 13] Avg. loss: 0.3730 | Mean IoU: 0.4072\n",
            ">>>> [Epoch: 14] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 14] Avg. loss: 0.3624 | Mean IoU: 0.4201\n",
            ">>>> [Epoch: 15] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 15] Avg. loss: 0.3424 | Mean IoU: 0.4287\n",
            ">>>> [Epoch: 16] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 16] Avg. loss: 0.3399 | Mean IoU: 0.4338\n",
            ">>>> [Epoch: 17] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 17] Avg. loss: 0.3371 | Mean IoU: 0.4370\n",
            ">>>> [Epoch: 18] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 18] Avg. loss: 0.3426 | Mean IoU: 0.4289\n",
            ">>>> [Epoch: 19] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 19] Avg. loss: 0.3176 | Mean IoU: 0.4483\n",
            ">>>> [Epoch: 19] Validation\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 19] Avg. loss: 0.3833 | Mean IoU: 0.4120\n",
            "unlabeled: 0.8785\n",
            "road: 0.1555\n",
            "sidewalk: 0.7861\n",
            "building: 0.2441\n",
            "wall: 0.0047\n",
            "fence: 0.7153\n",
            "pole: 0.0996\n",
            "traffic_light: nan\n",
            "traffic_sign: nan\n",
            "vegetation: nan\n",
            "terrain: nan\n",
            "sky: nan\n",
            "person: nan\n",
            "rider: nan\n",
            "car: nan\n",
            "truck: nan\n",
            "bus: nan\n",
            "train: nan\n",
            "motorcycle: nan\n",
            "bicycle: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 20] Avg. loss: 0.3063 | Mean IoU: 0.4531\n",
            ">>>> [Epoch: 21] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 21] Avg. loss: 0.3115 | Mean IoU: 0.4533\n",
            ">>>> [Epoch: 22] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 22] Avg. loss: 0.2887 | Mean IoU: 0.4703\n",
            ">>>> [Epoch: 23] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 23] Avg. loss: 0.2879 | Mean IoU: 0.4797\n",
            ">>>> [Epoch: 24] Training\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 24] Avg. loss: 0.2964 | Mean IoU: 0.4770\n",
            ">>>> [Epoch: 24] Validation\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/PyTorch-ENet-Training/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            ">>>> [Epoch: 24] Avg. loss: 0.4186 | Mean IoU: 0.4288\n",
            "unlabeled: 0.8833\n",
            "road: 0.2486\n",
            "sidewalk: 0.7756\n",
            "building: 0.2129\n",
            "wall: 0.0479\n",
            "fence: 0.7330\n",
            "pole: 0.1007\n",
            "traffic_light: nan\n",
            "traffic_sign: nan\n",
            "vegetation: nan\n",
            "terrain: nan\n",
            "sky: nan\n",
            "person: nan\n",
            "rider: nan\n",
            "car: nan\n",
            "truck: nan\n",
            "bus: nan\n",
            "train: nan\n",
            "motorcycle: nan\n",
            "bicycle: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}